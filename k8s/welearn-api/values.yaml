fullName: welearn-api

commonLabels:
  app.kubernetes.io/name: welearn-api
  app.kubernetes.io/component: api
  app.kubernetes.io/part-of: welearn
  app.kubernetes.io/managed-by: helm
  app.kubernetes.io/version: "{{ .Chart.AppVersion }}"

image:
  repository: criprodprod.azurecr.io
  path: welearn-api
  tag: "{{ .Values.application.revision }}"

replicaCount: 1

ingress:
  path: /

sablier:
  enabled: false
  groupName: welearn
  traefikMiddleware: "{{.Values.namespace}}-{{.Values.sablier.groupName}}-sablier@kubernetescrd"

resources:
  requests:
    cpu: 10m
    memory: 1471M
  limits:
    memory: 1508M

config:
  nonSensitive:
    CLIENT_ORIGINS_REGEX: '^{{ join "|" (values .Values.allowedHostsRegexes | sortAlpha ) }}$'
    AZURE_APIM_API_BASE: https://apim-welearn-mistral.azure-api.net/mistral/models
    AZURE_MISTRAL_API_BASE: https://welearn-mistral.services.ai.azure.com/models
    AZURE_API_BASE: "https://welearn-openai.openai.azure.com/openai/"
    AZURE_API_VERSION: "2024-08-01-preview"
    LLM_MODEL_NAME: gpt-oss-120b
    QDRANT_HOST: "http://qdrant.qdrant"
    QDRANT_PORT: "6333"
    MODELS_FOLDER_ROOTS: "/models"
    PG_USER: welearn_datastack
    PG_DATABASE: welearn_datastack
    PG_PORT: "5432"
    PG_DRIVER: postgresql+psycopg2

shareName: ml-models

runOnGpu: false # Schedule on the GPU node pool to lower its cost

allowedHostsRegexes:
  localhost: |-
    http:\/\/localhost:5173
